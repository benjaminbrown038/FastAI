{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjsEUXJnbzjWgya5H6sE9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/FastAI/blob/main/fastai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FastAI Tutorial - Deep Learning For Coders"
      ],
      "metadata": {
        "id": "E1KSSH0fYTUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Imports](#imports)\n",
        "\n",
        "\n",
        "[Data](#data)\n",
        "\n",
        "\n",
        "[Small Tutorial](#small_tutorial)\n",
        "\n",
        "\n",
        "[Functions](#functions)\n",
        "\n",
        "\n",
        "[Small Model](#small_model)\n"
      ],
      "metadata": {
        "id": "N9TpHfu7YqJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports\n",
        "<a name=\"imports\"></a>\n"
      ],
      "metadata": {
        "id": "eDvF24r-YfW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "from fastai.vision.all import *\n",
        "from fastai.callback.hook import *"
      ],
      "metadata": {
        "id": "ZXkFFR-3YU1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data\n",
        "<a name=\"data\"></a>"
      ],
      "metadata": {
        "id": "n1S3d_8bYU9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.PETS)/'images'\n",
        "dls = ImageDataLoaders.from_name_func(path,get_image_files(path),\n",
        "                                      valid_pct = .2,seed = 42,\n",
        "                                      label_func = is_cat,\n",
        "                                      item_tfms = Resize(224))\n"
      ],
      "metadata": {
        "id": "WZlDJce_YVDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Small Tutorial\n",
        "<a name=\"small_tutorial\"></a>"
      ],
      "metadata": {
        "id": "N2mxRnZWYVJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "time = torch.arange(0,20)\n",
        "params = torch.randn(3).requires_grad_()\n",
        "\n",
        "def apply_step(params,prn=True):\n",
        "    speed = time*3 + (time-9.5)**2 + 1\n",
        "    a,b,c = params\n",
        "    pred = a*(time**2) + b*time + 1\n",
        "    loss = ((pred - speed)**2).mean()\n",
        "    loss.backward()\n",
        "    lr = 1e-5\n",
        "    params.grad\n",
        "    params.data -= lr * params.grad.data\n",
        "    params.grad = None\n",
        "    if prn:\n",
        "        print(loss.item())\n",
        "        return pred"
      ],
      "metadata": {
        "id": "HWsHN0lmYVPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions\n",
        "<a name=\"functions\"></a>"
      ],
      "metadata": {
        "id": "uirzt5cXYVUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_cat(x):\n",
        "    return x[0].isupper()\n",
        "\n",
        "def L1_loss(average,real):\n",
        "    result = (average - real).abs().mean()\n",
        "    return result\n",
        "\n",
        "def mean_sq_error_loss(average,real):\n",
        "    result = ((average-real)**2).sqrt().mean()\n",
        "    return result\n",
        "\n",
        "# weigths\n",
        "def init_params(size,std=1.0):\n",
        "    params = (torch.randn(size)*std).requires_grad_()\n",
        "    return params\n",
        "\n",
        "# train\n",
        "def linear1(xb):\n",
        "    weights = xb@weights + bias\n",
        "    return weights\n",
        "\n",
        "# activation\n",
        "def sigmoid(x):\n",
        "    sig = 1/(1+torch.exp(-x))\n",
        "    return sig\n",
        "\n",
        "# loss\n",
        "def mnist_loss(predictions,targets):\n",
        "    predictions = predictions.sigmoid()\n",
        "    return torch.where(targets==1,1-predictions,predictions).mean()\n",
        "\n",
        "# train\n",
        "def calc_grad(xb,yb,model):\n",
        "    preds = model(xb)\n",
        "    loss = mnist_loss(preds,yb)\n",
        "    loss.backward()\n",
        "\n",
        "def batch_accuracy(xb,yb):\n",
        "    preds = xb.sigmoid()\n",
        "    correct = (preds > .5) == yb\n",
        "    result = correct.float().mean()\n",
        "    return result\n",
        "\n",
        "def validate_epoch(model):\n",
        "    accs = [batch_accuracy(model(xb),yb) for xb,yb in valid_dl]\n",
        "    result = round(torch.stack(accs).mean().item(),4)\n",
        "    return result\n",
        "\n",
        "# train\n",
        "def train_epoch(model,dl,opt):\n",
        "    for xb,yb in dl:\n",
        "        calc_grad(xb,yb,model)\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "# train\n",
        "def train_model(model,epochs):\n",
        "    for i in range(epochs):\n",
        "        train_epoch(model)\n",
        "        print(validate_epoch(model),end=' ')\n",
        "\n",
        "# train\n",
        "def simple_net(xb):\n",
        "    res = xb@w1 + b1\n",
        "    res = res.max(tensor(0.0))\n",
        "    res = res@w2 + b2\n",
        "    return res\n",
        "\n",
        "# loading data\n",
        "def load_data(folder_name):\n",
        "    training_tensor = [tensor(Image.open(i)) for i in folder_name]\n",
        "    training_stack = ((torch.stack(training_tensor)).float())\n",
        "    return training_stack\n",
        "\n",
        "# transforming data\n",
        "def training_data(*args):\n",
        "    training = (torch.cat(args))\n",
        "    return training\n",
        "\n",
        "# data information\n",
        "def size(training_stack):\n",
        "    size = ((training_stack.shape)[1]) * (training_stack.shape[2])\n",
        "    return size\n",
        "\n",
        "# creating data\n",
        "def init_weights(size):\n",
        "    weights = (torch.randn(size)).requires_grad_()\n",
        "    return weights\n",
        "\n",
        "# creating data\n",
        "def bias():\n",
        "    bias = torch.randn(1)\n",
        "    return bias\n",
        "\n",
        "# transforming data\n",
        "def transform_data_for_model(training_stack):\n",
        "    result = training_stack[1] * training_stack[2]\n",
        "    return result\n",
        "\n",
        "# transforming data\n",
        "def matrix_multiply(training_stack):\n",
        "    new_training_stack = (training_stack).view(-1,784)\n",
        "    pred = ((new_training_stack) @ weights) + bias\n",
        "    return pred\n",
        "\n",
        "# metric\n",
        "def loss(pred,target):\n",
        "    loss = (pred-target).abs().mean()\n",
        "    return loss\n",
        "\n",
        "# train\n",
        "def update(lr):\n",
        "    new_weights -= weights.grad * lr\n",
        "    return new_weights\n",
        "\n",
        "# data information\n",
        "def size_of_image(image):\n",
        "    image_size = image.shape\n",
        "    return image_size\n",
        "\n",
        "# data transformation\n",
        "def apply_kernel(row,col,kernel):\n",
        "    convolution = (img[row-1:row+2,col-1:col+2] * kernel).sum()\n",
        "    return convolution\n",
        "\n",
        "# transformation\n",
        "def convolution_top():\n",
        "    rng = (1,27)\n",
        "    top_edge = tensor([[apply_kernel(i,j,top_edge) for j in rng] for i in rng])\n",
        "    return top_edge\n",
        "\n",
        "# information\n",
        "def row(padding, stride, height):\n",
        "    new_row = (height + padding) // stride\n",
        "    return new_row\n",
        "\n",
        "# information\n",
        "def column(padding,stride,height):\n",
        "    new_column = (height + padding) // stride\n",
        "    return new_column\n",
        "\n",
        "# information\n",
        "def output_shape(w,n,p,f):\n",
        "    output = int((W - K + (2*P))/(S + 1))\n",
        "    new_output = (w - n + (2*p) - f) + 1\n",
        "    return new_output\n",
        "\n",
        "# creating kernels\n",
        "def top_edge():\n",
        "    top_edge = (tensor([1,1,1],[0,0,0],[-1,-1,-1])).float()\n",
        "    return top_edge\n",
        "\n",
        "# creating kernels\n",
        "def bottom_edge():\n",
        "    bottom_edge = (tensor([-1,-1,-1],[0,0,0],[1,1,1])).float()\n",
        "    return bottom_edge\n",
        "\n",
        "\n",
        "# creating kernels\n",
        "def right_edge():\n",
        "    right_edge = (tensor([-1,0,1],[-1,0,1],[-1,0,1])).float()\n",
        "    return right_edge\n",
        "\n",
        "# creating kernels\n",
        "def left_edge():\n",
        "    left_edge = (tensor([1,0,-1],[1,0,-1],[1,0,-1])).float()\n",
        "    return left_edge\n",
        "\n",
        "# creating kernels\n",
        "def diag1_edge():\n",
        "    diag1_edge = (tensor([1,0,-1],[0,1,0],[-1,0,1])).float()\n",
        "    return diag1_edge\n",
        "\n",
        "class BasicOptim:\n",
        "\n",
        "    def __init__(self,params,lr):\n",
        "        self.params,self.lr = list(params),lr\n",
        "\n",
        "    def step(self,*args,**kwargs):\n",
        "        for p in self.params:\n",
        "            p.data-=p.grad.data *self.lr\n",
        "\n",
        "    def zero_grad(self,*args,**kwargs):\n",
        "        for p in self.params:\n"
      ],
      "metadata": {
        "id": "_thKwO1R2zDR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Small Model \n",
        "<a name=\"small_model\"></a>\n"
      ],
      "metadata": {
        "id": "1udB3VGT2zJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = cnn_learner(dls,resnet34,metrics = error_rate)\n",
        "learn.fine_tune(1)"
      ],
      "metadata": {
        "id": "rKWINgwT2zOy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
